{"cells":[{"cell_type":"code","execution_count":58,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17559,"status":"ok","timestamp":1674576198860,"user":{"displayName":"Zuzanna Skorniewska","userId":"12442564233068447969"},"user_tz":0},"id":"IcoiGd6dJ9PP","outputId":"d9a9f706-194e-413d-a623-c9f1c20941ae"},"outputs":[],"source":["import chess\n","from random import randint,choice\n","\n","from torch.utils.data import Dataset,DataLoader,SubsetRandomSampler\n","from sklearn.model_selection import train_test_split\n","from torch.autograd import Variable\n","import numpy as np \n","from model import * \n","from tqdm import tqdm\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"markdown","metadata":{"id":"hN6b2WP-QD1V"},"source":["create multiple dataset classes, for different training tasks:\n","\n"," -- learn the next word - autoregressive task (if the model is to be a decoder based)\n","\n","\n"," For each of these we may have to modify the last linear layer of the model (to match dimensionality of the output) So maybe it should not be part of ChessEncoder but outside of it. \n","\n","the model needs to be changed to be a decoder model only - https://datascience.stackexchange.com/questions/65241/why-is-the-decoder-not-a-part-of-bert-architecture\n","\n","https://arxiv.org/pdf/2204.05832.pdf#:~:text=Decoder%2Donly%20models%20process%20a,decoder%20processes%20only%20the%20target.\n","\n","\n","google PaLM: https://arxiv.org/pdf/2204.02311.pdf\n"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":265,"status":"ok","timestamp":1674576378499,"user":{"displayName":"Zuzanna Skorniewska","userId":"12442564233068447969"},"user_tz":0},"id":"hC-R-BILKCea"},"outputs":[],"source":["\n","class LegalMovesBase(object):\n","\n","  def __init__(self,num_games:int=int(1e3),max_len:int=100):\n","    self.num_games = num_games\n","    self.max_len = max_len\n","    self.games_arr = []\n","\n","  def generate_games(self):\n","    games_arr = []\n","    print('This may take a while...Please wait.')\n","    for idx in tqdm(range(self.num_games)):\n","      board = chess.Board()\n","      #game = ['<START>']\n","      game = []\n","      game_over = False\n","      while game_over is False:\n","          move=board.lan(choice(list(board.legal_moves)))\n","          if '=' in move:\n","            move=move.replace('=','')\n","          board.push_san(move)\n","          game.append(move)\n","          game_over =  board.is_checkmate() or board.is_insufficient_material() or board.is_stalemate()\n","          if game_over:\n","              break\n","      #game.append('<END>')\n","      games_arr.extend(game)\n","    self.games_arr = games_arr\n","    \n","  \n","  def __getitem__(self, i):\n","        x = self.games_arr[i: i + self.max_len]\n","        y = self.games_arr[i+1: i+ self.max_len+1]\n","        return x, y\n","\n","  def __len__(self):\n","        return max((len(self.games_arr) - self.max_len),0)\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 1/1000 [00:00<02:44,  6.08it/s]"]},{"name":"stdout","output_type":"stream","text":["This may take a while...Please wait.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [02:08<00:00,  7.78it/s]\n"]}],"source":["dataset = LegalMovesBase()\n","dataset.generate_games()"]},{"cell_type":"code","execution_count":89,"metadata":{"id":"o8f4UNpiygml"},"outputs":[],"source":["valid_test_split = 0.4\n","random_seed= 31\n","batch_size = 100\n","data_size = len(dataset)\n","\n","# dividing training set to 0.6 of the total dataset\n","train_idx, valid_test_idx = train_test_split(np.arange(data_size),test_size=valid_test_split,shuffle=True)\n","\n","# dividing validation and test set to sets of equal size, i.e. each 0.2 of the total dataset\n","valid_idx, test_idx = train_test_split(valid_test_idx,test_size=0.5,shuffle=True)\n","\n","\n","train_sampler = SubsetRandomSampler(train_idx)\n","valid_sampler = SubsetRandomSampler(valid_idx)\n","test_sampler = SubsetRandomSampler(test_idx)\n","\n","train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n","validation_loader = DataLoader(dataset, batch_size=batch_size,sampler=valid_sampler)\n","test_loader = DataLoader(dataset, batch_size=batch_size,sampler=test_sampler)\n","\n"]},{"cell_type":"code","execution_count":90,"metadata":{"id":"mcxbW1BWh_2b"},"outputs":[],"source":["\n","def accuracy_score(predictions, labels,thresh=0.5):\n","    pred_labels = predictions.argmax(dim=-1)\n","    corrects = (pred_labels == labels)\n","    accuracy = corrects.sum().float() / float(labels.size(0))\n","    return accuracy.cpu().detach().numpy()\n","\n","\n","def run_epoch(train_mode,loader,epoch, model, optimizer, loss_fnc):\n","    epoch_metrics = {\n","        'epoch': epoch,\n","        'loss': 0.0,\n","        'n_batches': len(loader),\n","        'running_accuracy':0.0\n","    }\n","\n","    if train_mode:\n","        model.train()\n","    else:\n","        model.eval()\n","\n","    num_batches = len(loader)\n","\n","    msg= 'Training' if train_mode else 'Validation'\n","\n","\n","    for (X,target) in tqdm(loader, desc=f'{msg} epoch {epoch}', total=num_batches,position=0,leave=True):\n","        \n","        X,target = np.array(X).T,np.array(target).T\n","        target = model.embedding.translate_wti(target)\n","        target = Variable(torch.from_numpy(target)).type(torch.LongTensor)\n","\n","        if train_mode:\n","            optimizer.zero_grad()\n","\n","        output = model.forward(X)\n","        loss = loss_fnc(output.transpose(1,2), target)\n","        total_loss = loss.mean()\n","\n","        if train_mode:\n","            total_loss.backward()\n","            optimizer.step()\n","\n","                \n","        epoch_metrics['running_accuracy'] += accuracy_score(output,target)\n","\n","        epoch_metrics['loss'] += float(total_loss.cpu().detach().numpy())\n","\n","    epoch_metrics['loss'] = epoch_metrics['loss'] / epoch_metrics['n_batches']\n","    epoch_metrics['running_accuracy'] = epoch_metrics['running_accuracy']/epoch_metrics['n_batches']\n","    \n","    return epoch_metrics"]},{"cell_type":"code","execution_count":91,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Training epoch 0:   0%|          | 0/2280 [00:00<?, ?it/s]"]}],"source":["N_epochs=10\n","\n","model = ChessTransformer()\n","model = model.to(device)\n","optim = torch.optim.Adam(params=model.parameters())\n","loss_fnc = nn.CrossEntropyLoss()\n","\n","\n","train_log = np.zeros([N_epochs,2])\n","valid_log = np.zeros([N_epochs,2])\n","train_acc_curve = []\n","valid_acc_curve = []\n","for epoch in range(N_epochs):\n","  train_metrics = run_epoch(train_mode=True,loader=train_loader,epoch=epoch,model=model, optimizer=optim,loss_fnc = loss_fnc)\n","  torch.cuda.empty_cache()\n","  valid_metrics = run_epoch(train_mode=False,loader=validation_loader,epoch=epoch,model=model, optimizer=optim,loss_fnc = loss_fnc)\n","  torch.cuda.empty_cache()\n","\n","  print(\"\\n Metrics after epoch:{}\".format(epoch))\n","  print('\\n Training: loss: {}; accuracy: {}'.format(round(train_metrics['loss'],2),round(train_metrics['running_accuracy'],2)))\n","  print('\\n Validation: loss: {}; accuracy: {}'.format(round(valid_metrics['loss'],2),round(valid_metrics['running_accuracy'],2)))\n","\n","  train_log[epoch,:]=(train_metrics['loss'],train_metrics['running_accuracy'])"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["# todo: train an embeddding with <START> and <END> tokens\n","# and with additional moves as it does not contain all of them\n","\n","embed_path=\"chess_embedding/chess2vec.model\"\n","\n","embed_layer=Word2Vec.load(embed_path)"]},{"cell_type":"code","execution_count":83,"metadata":{},"outputs":[],"source":["\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMbhkEZG9c5oVhINwTX1JNl","provenance":[]},"kernelspec":{"display_name":"Python 3.9.0 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"},"vscode":{"interpreter":{"hash":"e1270bf742471f08454fdc592834658bbc8e48a81afcac5abe53248a989e7303"}}},"nbformat":4,"nbformat_minor":0}
